from flask import Flask, render_template, request, jsonify
import os
import re
import zipfile
from pathlib import Path
from werkzeug.utils import secure_filename
from datetime import datetime
import google.generativeai as genai
import json

# Configure Gemini API
genai.configure(api_key="AIzaSyCvXhsMX0EX1LNt5LGede-NSsHFF7wGTcU")

app = Flask(__name__)

# Configure upload folder
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'apk'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Load analysis results from file
ANALYSIS_FILE = 'apk_analysis_results.json'
learned_patterns = {}

# Create uploads folder if it doesn't exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

def load_learned_patterns():
    """Load learned patterns from analysis file if it exists"""
    global learned_patterns
    try:
        if os.path.exists(ANALYSIS_FILE):
            with open(ANALYSIS_FILE, 'r') as f:
                learned_patterns = json.load(f)
            print(f"Loaded learned patterns from {ANALYSIS_FILE}")
            return True
        else:
            # If we don't have an existing analysis file, try to generate one
            # Check if we have good and bad directories with APKs
            good_dir = "good"
            bad_dir = "bad"
            
            if os.path.exists(good_dir) and os.path.exists(bad_dir):
                good_apks = [f for f in os.listdir(good_dir) if f.endswith('.apk')]
                bad_apks = [f for f in os.listdir(bad_dir) if f.endswith('.apk')]
                
                if good_apks and bad_apks:
                    print(f"Found {len(good_apks)} good APKs and {len(bad_apks)} bad APKs. Analyzing differences...")
                    from apk_differentiator import analyze_directory_differences
                    results = analyze_directory_differences(good_dir, bad_dir)
                    
                    # Save results to a JSON file
                    with open(ANALYSIS_FILE, "w") as f:
                        json.dump(results, f, indent=2)
                    
                    learned_patterns = results
                    print(f"Generated and saved patterns to {ANALYSIS_FILE}")
                    return True
                else:
                    print("No APK files found in good/bad directories")
    except Exception as e:
        print(f"Error loading learned patterns: {str(e)}")
    
    # Return default patterns if loading fails
    learned_patterns = {
        "malicious_indicators": [
            "Combined file storage and internet access permissions",
            "File access with background services",
            "Starts automatically on device boot",
            "Contains possible encryption-related strings"
        ],
        "summary": {
            "good_apps": {
                "permissions": {"median": 5, "mean": 5.5},
                "services": {"median": 2, "mean": 2.5},
                "receivers": {"median": 2, "mean": 2.2}
            },
            "bad_apps": {
                "permissions": {"median": 9, "mean": 10.2},
                "services": {"median": 4, "mean": 5.1},
                "receivers": {"median": 4, "mean": 4.8}
            },
            "suspicious_permissions": [
                "SEND_SMS", "READ_SMS", "RECEIVE_SMS", "WRITE_EXTERNAL_STORAGE",
                "READ_EXTERNAL_STORAGE", "RECEIVE_BOOT_COMPLETED"
            ]
        }
    }
    print("Using default patterns as no learned patterns were available")
    return False

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def extract_features_from_apk(apk_path):
    """Extract features from APK using zip file analysis"""
    try:
        features = {}
        with zipfile.ZipFile(apk_path, 'r') as apk:
            # Get list of all files
            file_list = apk.namelist()

            # Extract AndroidManifest.xml
            try:
                manifest = apk.read('AndroidManifest.xml').decode('utf-8', errors='ignore')
            except:
                manifest = ""

            # Count total files
            features['total_files'] = len(file_list)

            # Count different file types
            features['dex_files'] = len([f for f in file_list if f.endswith('.dex')])
            features['jar_files'] = len([f for f in file_list if f.endswith('.jar')])
            features['so_files'] = len([f for f in file_list if f.endswith('.so')])
            features['xml_files'] = len([f for f in file_list if f.endswith('.xml')])
            features['png_files'] = len([f for f in file_list if f.endswith('.png')])
            features['jpg_files'] = len([f for f in file_list if f.endswith('.jpg')])
            features['txt_files'] = len([f for f in file_list if f.endswith('.txt')])

            # Check for common patterns in manifest
            permission_patterns = [
                'SEND_SMS', 'READ_SMS', 'RECEIVE_SMS', 'READ_CONTACTS',
                'INTERNET', 'READ_PHONE_STATE', 'ACCESS_FINE_LOCATION',
                'SYSTEM_ALERT_WINDOW', 'WRITE_EXTERNAL_STORAGE',
                'READ_EXTERNAL_STORAGE', 'RECEIVE_BOOT_COMPLETED',
                'REQUEST_IGNORE_BATTERY_OPTIMIZATIONS', 'WAKE_LOCK',
                'BIND_DEVICE_ADMIN', 'DISABLE_KEYGUARD',
                'ACCESS_COARSE_LOCATION', 'ACCESS_NETWORK_STATE',
                'CAMERA', 'RECORD_AUDIO', 'CHANGE_WIFI_STATE'
            ]

            for pattern in permission_patterns:
                features[f'has_{pattern.lower()}'] = 1 if pattern in manifest else 0

            # Count activities, services, and receivers
            features['activity_count'] = len(re.findall(r'<activity', manifest))
            features['service_count'] = len(re.findall(r'<service', manifest))
            features['receiver_count'] = len(re.findall(r'<receiver', manifest))
            features['provider_count'] = len(re.findall(r'<provider', manifest))

            # Check for potentially suspicious file names - removed 'su' and 'Superuser' from this list
            # as they can be legitimate in rooted device utility apps
            suspicious_files = [
                'rootkit', 'exploit', 'hack', 'crack', 'ransom', 'encrypt',
                'decrypt', 'bitcoin', 'payment', 'admin'
            ]

            for sus_file in suspicious_files:
                features[f'has_{sus_file}'] = 0
                for fname in file_list:
                    if sus_file.lower() in fname.lower():
                        features[f'has_{sus_file}'] = 1
                        break
            
            # Add separate checking for su/superuser files, but don't count these as automatically suspicious
            # Instead, we track them to contextualize the analysis
            features['has_su_files'] = 0
            su_related_files = []
            for fname in file_list:
                if 'su' in fname.lower() or 'superuser' in fname.lower() or 'root' in fname.lower():
                    features['has_su_files'] += 1
                    su_related_files.append(fname)
            
            features['su_related_files'] = su_related_files
                        
            # Check for encryption-related strings in any text files
            encryption_patterns = [
                'AES', 'RSA', 'encrypt', 'decrypt', 'key', 'crypto',
                'bitcoin', 'ransom', 'payment', 'unlock', 'lock', 'files'
            ]
            
            features['encryption_strings'] = 0
            for file_path in file_list:
                if file_path.endswith('.txt') or file_path.endswith('.xml') or file_path.endswith('.html'):
                    try:
                        content = apk.read(file_path).decode('utf-8', errors='ignore').lower()
                        for pattern in encryption_patterns:
                            if pattern.lower() in content:
                                features['encryption_strings'] += 1
                    except:
                        pass

            # Get APK size
            features['apk_size'] = Path(apk_path).stat().st_size / (1024*1024)  # Size in MB

            # Extract package name if possible
            package_match = re.search(r'package="([^"]+)"', manifest)
            if package_match:
                features['package_name'] = package_match.group(1)
            else:
                features['package_name'] = "unknown"

            # Count total permissions
            features['permission_count'] = sum(1 for k, v in features.items() 
                                             if k.startswith('has_') and not k.startswith('has_su') 
                                             and not k.startswith('has_exploit') and v == 1)

            # Get suspicious permissions
            suspicious_permissions = []
            for feature, value in features.items():
                if feature.startswith('has_') and value == 1:
                    permission_name = feature[4:].replace('_', ' ').upper()
                    suspicious_permissions.append(permission_name)
                    
            # File statistics for display
            file_stats = {
                'total_files': features['total_files'],
                'dex_files': features['dex_files'],
                'jar_files': features['jar_files'],
                'so_files': features['so_files'],
                'xml_files': features['xml_files'],
                'png_files': features['png_files'],
                'jpg_files': features['jpg_files'],
                'activity_count': features['activity_count'],
                'service_count': features['service_count'],
                'receiver_count': features['receiver_count'],
                'provider_count': features['provider_count'],
                'apk_size': features['apk_size'],
                'package_name': features['package_name'],
                'permission_count': features['permission_count'],
                'encryption_strings': features.get('encryption_strings', 0),
                'su_files_count': features.get('has_su_files', 0),
                'su_related_files': features.get('su_related_files', [])
            }

            return features, suspicious_permissions, file_stats

    except Exception as e:
        print(f"Error processing {apk_path}: {str(e)}")
        return None, None, None

def analyze_with_gemini(features, suspicious_permissions, file_stats):
    """Analyze APK using Gemini AI with learned patterns from good/bad analysis"""
    try:
        model = genai.GenerativeModel('gemini-1.5-pro')
        
        # Prepare malicious indicators based on our learned patterns
        detected_indicators = []
        potential_false_positives = []
        
        # Get baseline values from learned patterns if available
        good_baseline = learned_patterns.get('summary', {}).get('good_apps', {})
        bad_baseline = learned_patterns.get('summary', {}).get('bad_apps', {})
        
        # Otherwise use defaults
        if not good_baseline:
            good_baseline = {
                'permissions': {'median': 5, 'mean': 5.5},
                'services': {'median': 2, 'mean': 2.5},
                'receivers': {'median': 2, 'mean': 2.2}
            }
            
        if not bad_baseline:
            bad_baseline = {
                'permissions': {'median': 9, 'mean': 10.2},
                'services': {'median': 4, 'mean': 5.1},
                'receivers': {'median': 4, 'mean': 4.8}
            }
            
        # Get learned suspicious permissions
        suspicious_perms_list = learned_patterns.get('summary', {}).get('suspicious_permissions', [])
        if not suspicious_perms_list and 'suspicious_permissions' in learned_patterns:
            suspicious_perms_list = [p['permission'] for p in learned_patterns['suspicious_permissions'][:8]]
        
        # Create risk scores for different categories
        risk_scores = {
            "permissions": 0,
            "background_behavior": 0,
            "file_access": 0,
            "network": 0,
            "suspicious_content": 0
        }
        max_category_score = 10  # Maximum score per category
            
        # Check for combined storage permissions
        if features.get('has_read_external_storage', 0) == 1 and features.get('has_write_external_storage', 0) == 1:
            detected_indicators.append("Has complete file system access (read and write)")
            risk_scores["file_access"] += 5
            potential_false_positives.append("Many legitimate apps need file access for saving user data, documents, or media")
        
        # Check for file access + internet
        if (features.get('has_read_external_storage', 0) == 1 or features.get('has_write_external_storage', 0) == 1) and features.get('has_internet', 0) == 1:
            detected_indicators.append("Combines file access with internet connectivity")
            risk_scores["network"] += 4
            potential_false_positives.append("Cloud storage, social media, and file sharing apps legitimately require both file and internet access")
        
        # Check for boot receiver
        if features.get('has_receive_boot_completed', 0) == 1:
            detected_indicators.append("Starts automatically when device boots")
            risk_scores["background_behavior"] += 3
            potential_false_positives.append("System utilities, alarm apps, and messaging apps often need to start at boot")
        
        # Check for high service count
        if features['service_count'] >= bad_baseline.get('services', {}).get('median', 4):
            detected_indicators.append(f"High number of background services ({features['service_count']})")
            risk_scores["background_behavior"] += min(features['service_count'] - 3, 7)  # Cap at 7 points
            potential_false_positives.append("Complex apps like launchers, messaging apps, and system tools often use multiple services")
            
        # Check for high receiver count
        if features['receiver_count'] >= bad_baseline.get('receivers', {}).get('median', 4):
            detected_indicators.append(f"High number of broadcast receivers ({features['receiver_count']})")
            risk_scores["background_behavior"] += min(features['receiver_count'] - 3, 6)  # Cap at 6 points
            potential_false_positives.append("Apps that integrate with system events like SMS, calls, or network changes need multiple receivers")
        
        # Check for high permission count
        if features.get('permission_count', 0) >= bad_baseline.get('permissions', {}).get('median', 9):
            detected_indicators.append(f"Requests many permissions ({features.get('permission_count', 0)})")
            risk_scores["permissions"] += min(features.get('permission_count', 0) - 8, 8)  # Cap at 8 points
            potential_false_positives.append("Feature-rich apps like social media, camera apps, or navigation apps often require many permissions")
        
        # Check for encryption strings
        if features.get('encryption_strings', 0) > 0:
            detected_indicators.append(f"Contains {features.get('encryption_strings', 0)} encryption-related strings")
            risk_scores["suspicious_content"] += min(features.get('encryption_strings', 0) * 2, 7)  # Cap at 7 points
            potential_false_positives.append("Security apps, VPNs, and secure messaging apps legitimately use encryption")
        
        # Check for SMS permissions
        sms_permissions = features.get('has_send_sms', 0) == 1 or features.get('has_read_sms', 0) == 1 or features.get('has_receive_sms', 0) == 1
        if sms_permissions:
            detected_indicators.append("Has SMS permissions (could be used for premium SMS fraud)")
            risk_scores["permissions"] += 7
            potential_false_positives.append("SMS backup apps, messaging apps, and authentication apps legitimately need SMS access")
            
        # Check for suspicious files (excluding su/superuser files)
        suspicious_file_count = sum(1 for k, v in features.items() 
                                  if k.startswith('has_') and not k.startswith('has_su_') 
                                  and v == 1)
        if suspicious_file_count > 0:
            detected_indicators.append(f"Contains {suspicious_file_count} suspicious filenames")
            risk_scores["suspicious_content"] += min(suspicious_file_count * 3, 9)  # Cap at 9 points
        
        # Note SU-related files without treating them as necessarily malicious
        app_category = ""
        if features.get('has_su_files', 0) > 0:
            app_category = "Potential root utility app"
            potential_false_positives.append("Root utility apps legitimately contain files with names like 'su' or 'superuser'")
        
        # Cap each category at max score
        for category in risk_scores:
            risk_scores[category] = min(risk_scores[category], max_category_score)
        
        # Calculate overall risk score (0-100)
        # Weights: permissions (25%), background behavior (25%), file access (20%), network (15%), suspicious content (15%)
        overall_risk = (
            risk_scores["permissions"] * 2.5 +
            risk_scores["background_behavior"] * 2.5 +
            risk_scores["file_access"] * 2.0 +
            risk_scores["network"] * 1.5 +
            risk_scores["suspicious_content"] * 1.5
        )
        
        # Calculate benign likelihood (100 - risk, with adjustments)
        benign_likelihood = 100 - overall_risk
        
        # If it's likely a root app, adjust the benign likelihood
        if app_category == "Potential root utility app" and benign_likelihood < 60:
            benign_likelihood = max(benign_likelihood + 15, 60)  # Give root apps the benefit of the doubt
            
        # Generate API permissions list
        api_permissions = []
        for key, value in features.items():
            if key.startswith('has_') and value == 1:
                api_permissions.append(key[4:].upper())
        
        # Get learned guidance if available
        gemini_guidance = ""
        if 'gemini_prompt' in learned_patterns:
            gemini_guidance = learned_patterns['gemini_prompt']
            
        # Determine likely app categories based on permissions and features
        likely_categories = []
        
        if features.get('has_camera', 0) == 1:
            likely_categories.append("Camera/Photo")
        
        if features.get('has_record_audio', 0) == 1:
            likely_categories.append("Audio/Recording")
            
        if features.get('has_access_fine_location', 0) == 1:
            likely_categories.append("Maps/Navigation")
            
        if features.get('has_receive_boot_completed', 0) == 1 and features['service_count'] >= 3:
            likely_categories.append("System Utility")
            
        if features.get('has_internet', 0) == 1 and (features.get('has_read_external_storage', 0) == 1 or features.get('has_write_external_storage', 0) == 1):
            likely_categories.append("File Sharing/Cloud Storage")
            
        if sms_permissions:
            likely_categories.append("Messaging/Communication")
            
        if features.get('has_su_files', 0) > 0:
            likely_categories.append("Root Utility")
            
        # Create a prompt combining learned patterns and current analysis
        prompt = f"""
        You are an Android security expert specializing in APK analysis. I need you to provide a detailed technical report about this app's security profile. Avoid making a simple "malicious/benign" determination - instead provide a comprehensive analysis that helps users understand the potential risks and legitimate use cases.

        APK FEATURES:
        - Package name: {features.get('package_name', 'unknown')}
        - Total permissions requested: {features.get('permission_count', 0)} (typical good app: {good_baseline.get('permissions', {}).get('median', 5)}, typical bad app: {bad_baseline.get('permissions', {}).get('median', 9)})
        - Service count: {features.get('service_count', 0)} (typical good app: {good_baseline.get('services', {}).get('median', 2)}, typical bad app: {bad_baseline.get('services', {}).get('median', 4)})
        - Receiver count: {features.get('receiver_count', 0)} (typical good app: {good_baseline.get('receivers', {}).get('median', 2)}, typical bad app: {bad_baseline.get('receivers', {}).get('median', 4)})
        - Activity count: {features.get('activity_count', 0)}
        - DEX files: {features.get('dex_files', 0)}
        - Native libraries (SO files): {features.get('so_files', 0)}
        - Image resources (PNG+JPG): {(features.get('png_files', 0) or 0) + (features.get('jpg_files', 0) or 0)}
        - Encryption-related strings: {features.get('encryption_strings', 0)}
        - SU/Superuser related files: {features.get('has_su_files', 0)}
        
        PERMISSIONS:
        {', '.join(api_permissions) if api_permissions else 'None detected'}
        
        POTENTIAL CONCERNS DETECTED ({len(detected_indicators)}):
        {chr(10).join('- ' + indicator for indicator in detected_indicators) if detected_indicators else 'None detected'}
        
        POTENTIAL FALSE POSITIVES:
        {chr(10).join('- ' + fp for fp in potential_false_positives) if potential_false_positives else 'None identified'}
        
        RISK SCORES BY CATEGORY (0-10 scale):
        - Permissions risk: {risk_scores['permissions']}/10
        - Background behavior risk: {risk_scores['background_behavior']}/10
        - File access risk: {risk_scores['file_access']}/10
        - Network activity risk: {risk_scores['network']}/10
        - Suspicious content risk: {risk_scores['suspicious_content']}/10
        
        Overall risk score: {overall_risk:.1f}/100
        Benign likelihood: {benign_likelihood:.1f}%
        
        LIKELY APP CATEGORIES:
        {', '.join(likely_categories) if likely_categories else 'Unknown/Generic'}
        
        IMPORTANT CONTEXT: The app has {features.get('has_su_files', 0)} files related to superuser/root access. Many legitimate utility apps for rooted devices require SU permissions and contain files with "su" or "superuser" in their names. The presence of these files alone should not be considered malicious.
        
        {gemini_guidance if gemini_guidance else ''}
        
        Please provide a comprehensive security report in this JSON format:
        {{
          "executive_summary": "A 3-4 sentence high-level overview of the app's security profile",
          "detailed_analysis": {{
            "permissions_analysis": "Detailed analysis of the permissions requested by the app",
            "background_behavior_analysis": "Analysis of services, receivers, and boot behavior",
            "file_system_analysis": "Analysis of file system access patterns",
            "network_analysis": "Analysis of network capabilities",
            "code_content_analysis": "Analysis of suspicious strings and code patterns"
          }},
          "risk_assessment": {{
            "malicious_indicators": "Detailed explanation of potentially malicious indicators",
            "legitimate_use_cases": "Explanation of why these indicators might have legitimate purposes",
            "likelihood_assessment": "Assessment of how likely these indicators represent actual malicious behavior"
          }},
          "app_categorization": {{
            "likely_app_type": "What type of app this likely is based on features",
            "typical_behavior": "Is this behavior typical for this category of app?"
          }},
          "recommendations": {{
            "user_guidance": "What the user should know before installing this app",
            "security_precautions": "What precautions would be reasonable if using this app"
          }}
        }}
        
        In your analysis, avoid making absolute claims. Present a balanced view that acknowledges both security concerns and legitimate explanations.
        """
        
        # Send to Gemini and process response
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # Process Gemini response
        try:
            # Clean up response text to help with JSON parsing
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                cleaned_json = response_text[json_start:json_end]
                
                # Remove any comments that might break JSON parsing
                import re
                cleaned_json = re.sub(r'//.*', '', cleaned_json)
                
                # Try to parse as JSON
                import json
                result = json.loads(cleaned_json)
                
                # Add our analysis data to the result
                result["detected_indicators"] = detected_indicators
                result["potential_false_positives"] = potential_false_positives
                result["risk_scores"] = risk_scores
                result["overall_risk"] = overall_risk
                result["benign_likelihood"] = benign_likelihood
                result["likely_categories"] = likely_categories
                
                # If app_category isn't provided in the API response, use our detected value
                if "app_categorization" in result and "likely_app_type" in result["app_categorization"]:
                    app_category = result["app_categorization"]["likely_app_type"]
                else:
                    # Use our basic category detection
                    if "app_categorization" not in result:
                        result["app_categorization"] = {}
                    result["app_categorization"]["likely_app_type"] = app_category or ", ".join(likely_categories[:2])
                
                # For backward compatibility
                result["verdict"] = "DETAILED" 
                result["confidence"] = benign_likelihood / 100
                result["analysis"] = result.get("executive_summary", "Detailed analysis provided in report sections")
                result["concerns"] = "See detailed analysis for specific concerns"
                result["recommendations"] = result.get("recommendations", {}).get("user_guidance", "Review detailed report")
                result["app_category"] = app_category or ", ".join(likely_categories[:2])
                
                return result
                
        except Exception as e:
            print(f"Error parsing JSON: {str(e)}")
            # If JSON parsing fails, extract information using a more flexible approach
            
        # Fallback structured analysis if JSON parsing fails
        result = {
            "verdict": "DETAILED",
            "confidence": benign_likelihood / 100,
            "analysis": "Security analysis completed with detailed report sections.",
            "concerns": "See detailed analysis for specific concerns",
            "recommendations": "Review the complete security report for guidance",
            "detected_indicators": detected_indicators,
            "potential_false_positives": potential_false_positives,
            "app_category": app_category or ", ".join(likely_categories[:2]),
            "executive_summary": "This app shows a mixed security profile with both potential concerns and legitimate explanations.",
            "detailed_analysis": {
                "permissions_analysis": f"The app requests {features.get('permission_count', 0)} permissions, which is {'higher than' if features.get('permission_count', 0) > good_baseline.get('permissions', {}).get('median', 5) else 'typical for'} most legitimate apps.",
                "background_behavior_analysis": f"The app has {features.get('service_count', 0)} services and {features.get('receiver_count', 0)} receivers, which could enable background operation.",
                "file_system_analysis": "The app may have access to device storage, which should be considered when evaluating security implications.",
                "network_analysis": f"The app {'has' if features.get('has_internet', 0) == 1 else 'does not have'} internet access permissions.",
                "code_content_analysis": f"The analysis found {features.get('encryption_strings', 0)} encryption-related strings, which {'may be concerning' if features.get('encryption_strings', 0) > 0 else 'is not unusual'}."
            },
            "risk_assessment": {
                "malicious_indicators": f"The app shows {len(detected_indicators)} potential indicators that could suggest malicious behavior.",
                "legitimate_use_cases": "Many of these indicators could have legitimate explanations based on the app's functionality.",
                "likelihood_assessment": f"The app has a {benign_likelihood:.1f}% likelihood of being benign based on quantitative analysis."
            },
            "app_categorization": {
                "likely_app_type": app_category or ", ".join(likely_categories[:2]) or "Generic Application",
                "typical_behavior": "Some behaviors are typical for this category while others may warrant additional scrutiny."
            },
            "recommendations": {
                "user_guidance": "Consider the app's source, reviews, and developer reputation before installation.",
                "security_precautions": "Monitor the app's behavior after installation and be cautious about granting additional permissions."
            },
            "risk_scores": risk_scores,
            "overall_risk": overall_risk,
            "benign_likelihood": benign_likelihood,
            "likely_categories": likely_categories
        }
            
        return result
    
    except Exception as e:
        print(f"Error analyzing with Gemini: {str(e)}")
        return {
            "verdict": "DETAILED",
            "confidence": 0.5,
            "analysis": "Unable to generate AI analysis at this time due to an error.",
            "concerns": "Analysis unavailable",
            "recommendations": "Please try again later or consult with a security expert.",
            "detected_indicators": [],
            "potential_false_positives": [],
            "app_category": "",
            "executive_summary": "Analysis failed due to a technical error.",
            "detailed_analysis": {
                "permissions_analysis": "Analysis unavailable",
                "background_behavior_analysis": "Analysis unavailable",
                "file_system_analysis": "Analysis unavailable",
                "network_analysis": "Analysis unavailable",
                "code_content_analysis": "Analysis unavailable"
            },
            "risk_assessment": {
                "malicious_indicators": "Analysis unavailable",
                "legitimate_use_cases": "Analysis unavailable",
                "likelihood_assessment": "Analysis unavailable"
            },
            "app_categorization": {
                "likely_app_type": "Unknown",
                "typical_behavior": "Analysis unavailable"
            },
            "recommendations": {
                "user_guidance": "Analysis unavailable",
                "security_precautions": "Analysis unavailable"
            }
        }

# Flask route for the index page
@app.route('/')
def index():
    return render_template('index.html')

# Flask route for the analysis endpoint
@app.route('/analyze', methods=['POST'])
def analyze():
    if 'file' not in request.files:
        return jsonify({'error': 'No file uploaded'}), 400

    file = request.files['file']

    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400

    if not allowed_file(file.filename):
        return jsonify({'error': 'Invalid file type'}), 400

    try:
        # Save uploaded file
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # Extract features
        features, suspicious_permissions, file_stats = extract_features_from_apk(filepath)
        if features is None:
            raise Exception("Failed to extract features from APK")

        # Analyze with Gemini
        analysis_result = analyze_with_gemini(features, suspicious_permissions, file_stats)

        # Clean up uploaded file
        os.remove(filepath)

        # Add file stats to the result
        analysis_result['file_stats'] = file_stats
        analysis_result['suspicious_permissions'] = suspicious_permissions

        return jsonify(analysis_result)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Load learned patterns at startup
load_learned_patterns()

if __name__ == '__main__':
    print("Starting APK Security Analyzer with advanced analysis capabilities")
    
    # Create templates directory if it doesn't exist
    os.makedirs('templates', exist_ok=True)
    
    # Write the HTML template to the templates directory
    with open('templates/index.html', 'w', encoding='utf-8') as f:
        f.write('''<!DOCTYPE html>
<html>
<head>
    <title>APK Security Analyzer</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1, h2, h3, h4 {
            color: #333;
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
        }
        .upload-form {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background-color: #f9f9f9;
            border-radius: 8px;
        }
        .result {
            margin-top: 20px;
            padding: 20px;
            border-radius: 8px;
            display: none;
        }
        .loading {
            display: none;
            text-align: center;
            margin: 20px 0;
        }
        button {
            background-color: #4285f4;
            color: white;
            padding: 12px 24px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #3367d6;
        }
        input[type="file"] {
            padding: 10px;
            margin-right: 10px;
        }
        .report-section {
            margin: 25px 0;
            padding: 20px;
            background-color: #f9f9f9;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .report-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }
        .report-title {
            font-size: 20px;
            margin: 0;
        }
        .chart-container {
            margin: 20px 0;
            height: 300px;
        }
        .gauge-container {
            display: flex;
            justify-content: space-around;
            margin: 30px 0;
        }
        .gauge {
            text-align: center;
            width: 200px;
        }
        .indicator-list {
            background-color: #f0f0f0;
            border-radius: 4px;
            padding: 15px;
            margin: 10px 0;
        }
        .indicator-item {
            margin: 10px 0;
            padding-left: 20px;
            position: relative;
        }
        .indicator-item:before {
            content: "•";
            position: absolute;
            left: 0;
            color: #ff9800;
        }
        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        .card {
            background-color: white;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .category-tag {
            display: inline-block;
            background-color: #e0e0e0;
            padding: 5px 10px;
            border-radius: 16px;
            margin-right: 8px;
            margin-bottom: 8px;
            font-size: 14px;
        }
        .risk-meter {
            margin: 30px 0;
            text-align: center;
        }
        .risk-labels {
            display: flex;
            justify-content: space-between;
            margin-top: 5px;
            font-size: 14px;
        }
        .risk-label-low {
            color: green;
        }
        .risk-label-high {
            color: red;
        }
        .progress-bar {
            height: 20px;
            width: 100%;
            background-color: #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            border-radius: 10px;
            transition: width 0.5s;
        }
        .summary-box {
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            background-color: #f0f8ff;
            border-left: 5px solid #4285f4;
        }
        .file-stats {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
        }
        .stat-item {
            background-color: white;
            padding: 10px;
            border-radius: 4px;
            box-shadow: 0 1px 2px rgba(0,0,0,0.1);
        }
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            width: 36px;
            height: 36px;
            border-radius: 50%;
            border-left-color: #4285f4;
            animation: spin 1s linear infinite;
            margin: 20px auto;
        }
        .powered-by {
            text-align: center;
            margin-top: 30px;
            font-size: 14px;
            color: #666;
        }
        .false-positive {
            color: #0d47a1;
            font-style: italic;
        }
        .recommendations-box {
            background-color: #e8f5e9;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 5px solid #4caf50;
        }
        .permissions-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
            gap: 10px;
            margin: 15px 0;
        }
        .permission-item {
            background-color: #f5f5f5;
            padding: 8px 12px;
            border-radius: 4px;
            font-size: 14px;
        }
        .app-category {
            display: inline-block;
            background-color: #e8f5e9;
            padding: 8px 16px;
            border-radius: 20px;
            margin-bottom: 15px;
            font-weight: bold;
            color: #2e7d32;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        @media (max-width: 768px) {
            .two-column {
                grid-template-columns: 1fr;
            }
            .file-stats {
                grid-template-columns: 1fr 1fr;
            }
        }
        @media (max-width: 480px) {
            .file-stats {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>APK Security Analyzer</h1>
        <div class="upload-form">
            <h2>Upload an APK for Security Analysis</h2>
            <p>Our advanced AI will analyze the APK for potential security concerns and give you a detailed report.</p>
            <form id="uploadForm" enctype="multipart/form-data">
                <input type="file" id="apkFile" accept=".apk" required>
                <button type="submit">Analyze APK</button>
            </form>
        </div>
        <div id="loading" class="loading">
            <div class="spinner"></div>
            <p>Analyzing APK... This may take a moment...</p>
        </div>
        <div id="result" class="result"></div>
        <div class="powered-by">
            Powered by Google Gemini AI • Advanced Security Analysis
        </div>
    </div>

    <script>
        document.getElementById('uploadForm').onsubmit = function(e) {
            e.preventDefault();

            const formData = new FormData();
            const fileInput = document.getElementById('apkFile');
            const file = fileInput.files[0];

            if (!file) {
                alert('Please select an APK file');
                return;
            }

            formData.append('file', file);

            document.getElementById('loading').style.display = 'block';
            document.getElementById('result').style.display = 'none';

            fetch('/analyze', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                renderDetailedReport(data);
            })
            .catch(error => {
                alert('Error analyzing APK: ' + error);
            })
            .finally(() => {
                document.getElementById('loading').style.display = 'none';
            });
        };

        function renderDetailedReport(data) {
            const resultDiv = document.getElementById('result');
            
            // Create the main report structure
            let reportHtml = `
                <h2>Security Analysis Report</h2>
                <div class="app-category">${data.app_category || 'Generic Application'}</div>
                
                <!-- Summary Section -->
                <div class="summary-box">
                    <h3>Executive Summary</h3>
                    <p>${data.executive_summary || data.analysis}</p>
                </div>
                
                <!-- Risk Assessment Gauge -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">Risk Assessment</h3>
                    </div>
                    
                    <div class="risk-meter">
                        <h4>Overall Security Risk</h4>
                        <div class="progress-bar">
                            <div class="progress-fill" id="risk-meter-fill" style="width: ${data.overall_risk || 50}%; background: linear-gradient(90deg, #4caf50, #ffeb3b, #f44336);"></div>
                        </div>
                        <div class="risk-labels">
                            <span class="risk-label-low">Low Risk (0%)</span>
                            <span>Moderate Risk (50%)</span>
                            <span class="risk-label-high">High Risk (100%)</span>
                        </div>
                    </div>
                    
                    <div class="two-column">
                        <div class="card">
                            <h4>Benign App Likelihood</h4>
                            <div class="chart-container">
                                <canvas id="likelihoodChart"></canvas>
                            </div>
                        </div>
                        <div class="card">
                            <h4>Risk Categories</h4>
                            <div class="chart-container">
                                <canvas id="riskCategoriesChart"></canvas>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Detailed Analysis Section -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">Detailed Analysis</h3>
                    </div>
                    
                    <div class="card">
                        <h4>Permissions Analysis</h4>
                        <p>${data.detailed_analysis?.permissions_analysis || 'No permissions analysis available'}</p>
                        
                        <h4>Permissions Requested:</h4>
                        <div class="permissions-grid">
                            ${data.suspicious_permissions ? data.suspicious_permissions.map(p => `<div class="permission-item">${p}</div>`).join('') : 'No permissions detected'}
                        </div>
                    </div>
                    
                    <div class="two-column" style="margin-top: 20px;">
                        <div class="card">
                            <h4>Background Behavior</h4>
                            <p>${data.detailed_analysis?.background_behavior_analysis || 'No background behavior analysis available'}</p>
                        </div>
                        <div class="card">
                            <h4>File System Access</h4>
                            <p>${data.detailed_analysis?.file_system_analysis || 'No file system analysis available'}</p>
                        </div>
                    </div>
                    
                    <div class="two-column" style="margin-top: 20px;">
                        <div class="card">
                            <h4>Network Capabilities</h4>
                            <p>${data.detailed_analysis?.network_analysis || 'No network analysis available'}</p>
                        </div>
                        <div class="card">
                            <h4>Code Content Analysis</h4>
                            <p>${data.detailed_analysis?.code_content_analysis || 'No code content analysis available'}</p>
                        </div>
                    </div>
                </div>
                
                <!-- Indicators Section -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">Detected Indicators</h3>
                    </div>
                    
                    <div class="two-column">
                        <div class="card">
                            <h4>Potential Security Concerns (${data.detected_indicators ? data.detected_indicators.length : 0})</h4>
                            ${renderIndicatorsList(data.detected_indicators)}
                        </div>
                        <div class="card">
                            <h4>Potential False Positives</h4>
                            ${renderFalsePositivesList(data.potential_false_positives)}
                        </div>
                    </div>
                </div>
                
                <!-- Risk Assessment Section -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">Risk Assessment</h3>
                    </div>
                    
                    <div class="card">
                        <h4>Malicious Indicators</h4>
                        <p>${data.risk_assessment?.malicious_indicators || 'No specific malicious indicators identified'}</p>
                        
                        <h4>Legitimate Use Cases</h4>
                        <p>${data.risk_assessment?.legitimate_use_cases || 'No specific legitimate use cases identified'}</p>
                        
                        <h4>Likelihood Assessment</h4>
                        <p>${data.risk_assessment?.likelihood_assessment || 'No likelihood assessment available'}</p>
                    </div>
                </div>
                
                <!-- App Categorization Section -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">App Categorization</h3>
                    </div>
                    
                    <div class="card">
                        <h4>Likely App Type</h4>
                        <p>${data.app_categorization?.likely_app_type || 'Unknown app type'}</p>
                        
                        <h4>Likely Categories</h4>
                        <div>
                            ${renderCategories(data.likely_categories)}
                        </div>
                        
                        <h4>Typical Behavior Assessment</h4>
                        <p>${data.app_categorization?.typical_behavior || 'No behavior assessment available'}</p>
                    </div>
                </div>
                
                <!-- Recommendations Section -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">Recommendations</h3>
                    </div>
                    
                    <div class="recommendations-box">
                        <h4>User Guidance</h4>
                        <p>${data.recommendations?.user_guidance || data.recommendations || 'No specific guidance available'}</p>
                        
                        <h4>Security Precautions</h4>
                        <p>${data.recommendations?.security_precautions || 'No specific security precautions recommended'}</p>
                    </div>
                </div>
                
                <!-- Technical Details Section -->
                <div class="report-section">
                    <div class="report-header">
                        <h3 class="report-title">Technical Details</h3>
                    </div>
                    
                    <div class="card">
                        <h4>File Statistics</h4>
                        <div class="file-stats">
                            <div class="stat-item">Package: <strong>${data.file_stats?.package_name || 'Unknown'}</strong></div>
                            <div class="stat-item">Permissions: <strong>${data.file_stats?.permission_count || 0}</strong></div>
                            <div class="stat-item">APK Size: <strong>${data.file_stats?.apk_size ? data.file_stats.apk_size.toFixed(2) + ' MB' : 'Unknown'}</strong></div>
                            <div class="stat-item">Total Files: <strong>${data.file_stats?.total_files || 0}</strong></div>
                            <div class="stat-item">DEX Files: <strong>${data.file_stats?.dex_files || 0}</strong></div>
                            <div class="stat-item">Native Libraries: <strong>${data.file_stats?.so_files || 0}</strong></div>
                            <div class="stat-item">Activities: <strong>${data.file_stats?.activity_count || 0}</strong></div>
                            <div class="stat-item">Services: <strong>${data.file_stats?.service_count || 0}</strong></div>
                            <div class="stat-item">Receivers: <strong>${data.file_stats?.receiver_count || 0}</strong></div>
                            <div class="stat-item">Providers: <strong>${data.file_stats?.provider_count || 0}</strong></div>
                            <div class="stat-item">Image Files: <strong>${((data.file_stats?.png_files || 0) + (data.file_stats?.jpg_files || 0))}</strong></div>
                            <div class="stat-item">Encryption Strings: <strong>${data.file_stats?.encryption_strings || 0}</strong></div>
                            <div class="stat-item">SU Files: <strong>${data.file_stats?.su_files_count || 0}</strong></div>
                        </div>
                        
                        ${data.file_stats?.su_related_files && data.file_stats.su_related_files.length > 0 ? `
                        <div style="margin-top: 20px;">
                            <h4>Root/SU Related Files (${data.file_stats.su_files_count})</h4>
                            <p>These files may indicate a root utility app, which is legitimate for rooted devices:</p>
                            <ul>
                                ${data.file_stats.su_related_files.map(file => `<li>${file}</li>`).join('')}
                            </ul>
                        </div>
                        ` : ''}
                    </div>
                </div>
            `;
            
            resultDiv.innerHTML = reportHtml;
            resultDiv.style.display = 'block';
            
            // Render the charts
            renderLikelihoodChart(data.benign_likelihood || 50);
            renderRiskCategoriesChart(data.risk_scores);
        }
        
        function renderIndicatorsList(indicators) {
            if (!indicators || indicators.length === 0) {
                return '<p>No specific indicators detected.</p>';
            }
            
            let html = '<div class="indicator-list">';
            indicators.forEach(indicator => {
                html += `<div class="indicator-item">${indicator}</div>`;
            });
            html += '</div>';
            
            return html;
        }
        
        function renderFalsePositivesList(falsePositives) {
            if (!falsePositives || falsePositives.length === 0) {
                return '<p>No specific false positives identified.</p>';
            }
            
            let html = '<div class="indicator-list">';
            falsePositives.forEach(fp => {
                html += `<div class="indicator-item false-positive">${fp}</div>`;
            });
            html += '</div>';
            
            return html;
        }
        
        function renderCategories(categories) {
            if (!categories || categories.length === 0) {
                return '<p>No specific categories identified.</p>';
            }
            
            let html = '<div style="margin-top: 10px;">';
            categories.forEach(category => {
                html += `<span class="category-tag">${category}</span>`;
            });
            html += '</div>';
            
            return html;
        }
        
        function renderLikelihoodChart(benignLikelihood) {
            const ctx = document.getElementById('likelihoodChart');
            if (!ctx) return;
            
            new Chart(ctx, {
                type: 'doughnut',
                data: {
                    labels: ['Benign Likelihood', 'Risk Potential'],
                    datasets: [{
                        data: [benignLikelihood, 100 - benignLikelihood],
                        backgroundColor: ['#4caf50', '#f44336'],
                        borderWidth: 0
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    cutout: '70%',
                    plugins: {
                        legend: {
                            position: 'bottom'
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `${context.label}: ${context.raw}%`;
                                }
                            }
                        }
                    }
                }
            });
        }
        
        function renderRiskCategoriesChart(riskScores) {
            const ctx = document.getElementById('riskCategoriesChart');
            if (!ctx || !riskScores) return;
            
            const labels = Object.keys(riskScores).map(key => {
                return key.replace('_', ' ').split(' ').map(word => 
                    word.charAt(0).toUpperCase() + word.slice(1)
                ).join(' ');
            });
            
            const values = Object.values(riskScores);
            
            new Chart(ctx, {
                type: 'radar',
                data: {
                    labels: labels,
                    datasets: [{
                        label: 'Risk Score (0-10)',
                        data: values,
                        fill: true,
                        backgroundColor: 'rgba(255, 99, 132, 0.2)',
                        borderColor: 'rgb(255, 99, 132)',
                        pointBackgroundColor: 'rgb(255, 99, 132)',
                        pointBorderColor: '#fff',
                        pointHoverBackgroundColor: '#fff',
                        pointHoverBorderColor: 'rgb(255, 99, 132)'
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        r: {
                            angleLines: {
                                display: true
                            },
                            suggestedMin: 0,
                            suggestedMax: 10
                        }
                    }
                }
            });
        }
    </script>
</body>
</html>''')
    
    # Run the app
    app.run(debug=True, port=5000)
        